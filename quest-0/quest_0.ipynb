{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set device as GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    dev = 'mps'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)    \n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch warmup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use torch.randn to create two tensors of size (29, 30, 32) and (32, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of Size (29, 30, 32): \n",
      " tensor([[[-2.1067e-01, -3.0875e-01, -1.3734e+00,  ..., -1.7303e+00,\n",
      "           1.2111e+00, -2.0044e-01],\n",
      "         [ 1.3123e+00, -5.7135e-01,  1.7700e-01,  ..., -8.0103e-01,\n",
      "          -6.7393e-01,  1.3656e+00],\n",
      "         [ 1.5708e+00, -1.7066e-02,  1.6031e-01,  ..., -3.8322e+00,\n",
      "          -9.3773e-01, -3.4475e-01],\n",
      "         ...,\n",
      "         [-2.9619e-01, -1.1388e+00, -1.1130e+00,  ..., -2.9467e-01,\n",
      "          -2.2069e-01, -3.3374e-01],\n",
      "         [-2.6296e-01,  6.9993e-01,  1.5886e+00,  ...,  1.8364e-01,\n",
      "          -1.5700e-01,  1.9368e+00],\n",
      "         [-7.3116e-01, -2.0066e-01,  6.8950e-01,  ..., -9.3666e-02,\n",
      "           1.6251e+00, -9.8816e-01]],\n",
      "\n",
      "        [[-6.6202e-01, -1.2947e-01,  1.8109e+00,  ...,  1.3224e+00,\n",
      "          -2.4159e-01, -1.8256e+00],\n",
      "         [ 6.0416e-01, -7.1181e-02,  1.5761e+00,  ...,  2.5279e-01,\n",
      "          -1.6321e+00,  4.1178e-01],\n",
      "         [ 6.8480e-02, -3.9542e-01, -1.5634e+00,  ...,  2.3276e+00,\n",
      "           2.0832e+00, -5.4889e-01],\n",
      "         ...,\n",
      "         [-4.4977e-01, -3.2193e-01, -9.2664e-01,  ...,  1.8712e+00,\n",
      "          -5.3838e-01, -4.1453e-01],\n",
      "         [ 1.2633e+00,  5.1548e-01, -4.5982e-01,  ...,  1.2739e-01,\n",
      "           1.5945e+00, -1.6824e+00],\n",
      "         [ 9.1172e-02,  2.5966e-01,  3.5048e-01,  ..., -2.3646e-02,\n",
      "           4.4107e-01, -2.9149e-01]],\n",
      "\n",
      "        [[ 3.5048e-01, -7.2776e-02, -9.5242e-01,  ...,  8.9225e-01,\n",
      "          -1.0360e-01,  1.0893e+00],\n",
      "         [-5.5376e-01, -1.3994e+00, -5.3123e-02,  ...,  1.2422e+00,\n",
      "           6.5130e-01,  1.1610e+00],\n",
      "         [-2.8739e+00,  5.3464e-01,  1.4638e+00,  ...,  6.3556e-01,\n",
      "          -3.5700e-01,  1.1469e-01],\n",
      "         ...,\n",
      "         [-3.1873e-03,  1.6276e+00, -7.7793e-02,  ..., -1.2421e+00,\n",
      "           4.5291e-01, -5.3263e-01],\n",
      "         [-7.7588e-01, -4.2752e-01, -3.7907e-01,  ..., -1.4306e+00,\n",
      "           3.8938e-01, -2.7451e-01],\n",
      "         [ 1.8716e-01,  3.8986e-01,  1.6629e+00,  ..., -1.3502e+00,\n",
      "           3.4526e-01, -9.6382e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.7973e-01,  9.1755e-02, -5.6728e-01,  ...,  7.3500e-01,\n",
      "          -1.7774e+00,  1.2224e+00],\n",
      "         [-1.4489e+00,  1.1618e+00, -1.5141e+00,  ..., -3.2819e-02,\n",
      "          -5.5056e-02, -3.0720e-01],\n",
      "         [ 5.7253e-01,  3.5567e-01, -5.7811e-01,  ..., -2.1189e+00,\n",
      "          -1.0893e+00, -5.2937e-01],\n",
      "         ...,\n",
      "         [-4.7004e-01, -4.0298e-01, -5.9413e-02,  ..., -5.7979e-02,\n",
      "           7.3937e-01, -3.5294e-01],\n",
      "         [-1.9285e-01, -1.6521e-01, -1.5988e+00,  ..., -9.0956e-01,\n",
      "           4.2901e-01,  1.8444e+00],\n",
      "         [-4.6306e-01,  1.7627e+00,  4.7907e-01,  ...,  8.7384e-03,\n",
      "          -4.2139e-01,  5.4632e-02]],\n",
      "\n",
      "        [[-2.1167e-01,  2.0462e-01, -8.8463e-01,  ...,  2.8251e-01,\n",
      "           8.7382e-01,  7.8965e-01],\n",
      "         [-1.6196e-01,  1.1027e-01, -2.0127e-02,  ..., -2.8730e-01,\n",
      "           6.5135e-01,  1.6500e+00],\n",
      "         [ 1.8941e-01,  2.3203e+00,  1.1567e-01,  ..., -4.6361e-01,\n",
      "           4.7927e-01, -4.5759e-01],\n",
      "         ...,\n",
      "         [ 5.2161e-01, -7.6744e-01, -6.7863e-01,  ..., -1.3421e+00,\n",
      "           9.2497e-02, -6.5636e-01],\n",
      "         [-4.1702e-01,  1.6977e-02, -8.6467e-01,  ...,  6.4705e-02,\n",
      "           2.6690e-01,  1.5385e-01],\n",
      "         [-1.5565e+00, -5.3168e-01,  1.9936e-02,  ...,  4.6980e-01,\n",
      "          -1.8774e+00,  1.7410e+00]],\n",
      "\n",
      "        [[ 5.5726e-01,  2.3510e-01,  3.0158e-01,  ..., -9.7169e-01,\n",
      "           1.1631e+00, -6.9993e-01],\n",
      "         [ 1.2455e+00,  1.0154e-01,  1.6078e+00,  ...,  6.1219e-01,\n",
      "           1.0539e+00,  8.9917e-01],\n",
      "         [-4.5559e-01,  4.6343e-01, -9.9505e-01,  ..., -7.7707e-02,\n",
      "          -7.2877e-01, -5.2259e-01],\n",
      "         ...,\n",
      "         [ 7.4435e-01, -1.0011e+00,  3.3487e-01,  ...,  1.1517e+00,\n",
      "          -9.4156e-01,  1.3647e+00],\n",
      "         [-7.3430e-01,  1.4741e+00, -7.5634e-01,  ...,  6.0590e-01,\n",
      "          -3.1700e-02, -1.7570e+00],\n",
      "         [ 3.5870e-02, -4.1674e-01, -2.8444e-01,  ..., -1.7561e+00,\n",
      "          -1.0423e+00,  7.4571e-02]]])\n",
      "Tensor of Size (32, 100): \n",
      " tensor([[-1.1976,  0.8582,  0.2887,  ...,  0.6910,  0.2395, -0.1267],\n",
      "        [-0.8541, -1.7190,  1.7795,  ...,  0.1657,  0.6181, -0.5361],\n",
      "        [-0.9553, -0.9835, -1.2239,  ...,  0.0077,  0.5828,  0.4778],\n",
      "        ...,\n",
      "        [-2.3713,  0.7050, -0.4258,  ...,  0.5413,  0.1573, -1.0333],\n",
      "        [ 0.4026,  2.2841, -0.5050,  ...,  0.1473,  0.1000,  0.6233],\n",
      "        [ 0.4906, -1.4748, -0.7984,  ..., -1.7977,  0.1157,  1.0350]])\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randn(29, 30, 32)\n",
    "print('Tensor of Size (29, 30, 32): \\n' , tensor_a)\n",
    "\n",
    "tensor_b = torch.randn(32, 100)\n",
    "print('Tensor of Size (32, 100): \\n' , tensor_b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use  torch.matmul  to matrix multiply the two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product of tensor_a and tensor_b: \n",
      " tensor([[[  0.7419,  -6.8593,  -5.6530,  ...,  -2.0349,   2.4414,   2.7202],\n",
      "         [ -2.0525,  -1.0605,   1.5309,  ...,  -2.1761,  -9.4649,   5.6621],\n",
      "         [  1.0493,   4.3634,   5.6647,  ...,   0.6152,  -1.0595,  -1.3253],\n",
      "         ...,\n",
      "         [ -2.0524,  -0.0474,  10.1518,  ...,  -6.3781,  -0.3214,   4.9168],\n",
      "         [  0.8337,   4.8886,  -4.8482,  ...,   1.5900,  -1.4781, -16.4335],\n",
      "         [  6.8869,  -2.4298,   6.2692,  ...,  -7.8960,  -8.9709,  13.8102]],\n",
      "\n",
      "        [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "         [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "         [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "         ...,\n",
      "         [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "         [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "         [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "        [[  6.1546,   0.7146,   2.1322,  ...,  -4.5322,  -0.1707,  -4.5282],\n",
      "         [  5.9549, -10.3146,  -1.0091,  ...,   1.8014,   5.4770,  -2.0132],\n",
      "         [  1.0229,  -2.9217,   6.4467,  ...,   7.3697,  -1.7195,  12.6359],\n",
      "         ...,\n",
      "         [ -6.4925,  -3.8809,  -2.3571,  ...,  -3.6958,   7.8894,  -8.6069],\n",
      "         [  3.0474,  -2.9584,   1.4904,  ...,   1.5481,   7.2212, -10.0925],\n",
      "         [  0.0166,  10.6724,   0.1993,  ...,  11.7513,   1.0871,   1.5053]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  2.6810,  -4.3125,  -1.8347,  ..., -12.3051,   2.4593,  -4.0132],\n",
      "         [ -0.4259,  -0.5535,  -3.3544,  ...,   1.7058,  -3.8773,  -5.1241],\n",
      "         [-11.0149,  -3.3008,  -3.6872,  ...,   1.6458,   8.3347,  -3.1148],\n",
      "         ...,\n",
      "         [  3.6411, -13.9457,   2.9425,  ..., -11.4886,  -8.2979,  -5.2767],\n",
      "         [ -1.3502,   6.5703,  11.5629,  ...,  -1.4349,  -1.2074,   6.3165],\n",
      "         [  2.6934,   2.0616,  -0.6348,  ...,  -3.7450,   0.5671,   0.8650]],\n",
      "\n",
      "        [[  2.7736,  -1.4151,   4.0755,  ..., -11.7215,  -4.3883,   4.5976],\n",
      "         [  4.5642,  -1.2270,   7.2177,  ...,   1.6591,  -0.7404,   1.1020],\n",
      "         [ -7.7290,   4.4398,   3.1149,  ...,   5.1482,   2.5751,   9.8370],\n",
      "         ...,\n",
      "         [  6.3003,  -0.6190,  -5.1802,  ...,   4.2852,  -1.2074,   7.4648],\n",
      "         [ -2.9038,  -0.8584,  -5.1471,  ...,   1.2670,  -0.4973,  -0.9703],\n",
      "         [  1.8961,  -2.9697,   9.3500,  ...,  -7.1284,  -1.8419,  -0.6842]],\n",
      "\n",
      "        [[-10.0955,   3.9633,  -8.4298,  ...,  -2.9574, -12.3479,  11.4634],\n",
      "         [  5.7856,   4.0575,  -1.1645,  ...,  -4.4277,  -0.2743,  -5.9354],\n",
      "         [ -6.6147,   5.3965,   2.0963,  ...,   3.1064,  -1.1301,  -0.8767],\n",
      "         ...,\n",
      "         [  1.9751,   6.1068,   6.5911,  ...,  -9.8484,  -1.8429,  -7.2884],\n",
      "         [ -2.4903,   0.6457,  -2.0200,  ..., -11.5766,  -3.9897,  -4.1240],\n",
      "         [  0.2536,  -0.3082,  -3.5614,  ...,   8.9747,   4.6388,   0.4851]]])\n",
      "Shape of Tensor:  torch.Size([29, 30, 100])\n"
     ]
    }
   ],
   "source": [
    "product = torch.matmul(tensor_a, tensor_b)\n",
    "print('Product of tensor_a and tensor_b: \\n' , product)\n",
    "\n",
    "print('Shape of Tensor: ' , product.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the difference between torch.matmul , torch.mm , torch.bmm , and torch.einsum , and the @ operator?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use torch.sum on the resulting tensor, passing the optional argument of dim=1 to sum across the 1st dimension. Before you run this, can you predict the size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Tensor across 1st Dimension: \n",
      " tensor([[  4.3803,  27.6355,  10.4532,  ..., -20.4508, -52.5161,  18.6207],\n",
      "        [-34.0304,  -4.0265,   1.2697,  ...,  37.4259,  24.8413, -44.9415],\n",
      "        [ 37.1351,  -8.9411,  -3.3288,  ...,  24.2283,  76.8887,  15.5597],\n",
      "        ...,\n",
      "        [ 42.7140, -27.5872, -16.2978,  ..., -45.1092,  -6.5104, -15.0116],\n",
      "        [ 33.6693, -51.0728,  43.5822,  ..., -30.6077,  -2.3664,  34.3853],\n",
      "        [-25.3936,  16.8425, -23.8186,  ...,  -4.3446, -29.2025,  -1.0167]])\n",
      "Shape of Tensor:  torch.Size([29, 100])\n"
     ]
    }
   ],
   "source": [
    "tensor_sum = torch.sum(product, dim = 1)\n",
    "print('Sum of Tensor across 1st Dimension: \\n' , tensor_sum)\n",
    "\n",
    "print('Shape of Tensor: ' , tensor_sum.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a new long tensor of size  (3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Tensor: \n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Updated Long Tensor: \n",
      " tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 4, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 6, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "long_tensor = torch.ones((3, 10), dtype = torch.long)\n",
    "print('Long Tensor: \\n' , long_tensor)\n",
    "\n",
    "long_tensor[0, 0] = 2\n",
    "long_tensor[1, 2] = 4\n",
    "long_tensor[2, 4] = 6\n",
    "\n",
    "print('Updated Long Tensor: \\n' , long_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use this new long tensor to index into the tensor from step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed Tensor: \n",
      " tensor([[[[  6.1546,   0.7146,   2.1322,  ...,  -4.5322,  -0.1707,  -4.5282],\n",
      "          [  5.9549, -10.3146,  -1.0091,  ...,   1.8014,   5.4770,  -2.0132],\n",
      "          [  1.0229,  -2.9217,   6.4467,  ...,   7.3697,  -1.7195,  12.6359],\n",
      "          ...,\n",
      "          [ -6.4925,  -3.8809,  -2.3571,  ...,  -3.6958,   7.8894,  -8.6069],\n",
      "          [  3.0474,  -2.9584,   1.4904,  ...,   1.5481,   7.2212, -10.0925],\n",
      "          [  0.0166,  10.6724,   0.1993,  ...,  11.7513,   1.0871,   1.5053]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]]],\n",
      "\n",
      "\n",
      "        [[[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[ -0.4746,  -1.1052,  10.6652,  ...,  -4.3976, -10.8124,  -9.5936],\n",
      "          [ -0.9490,   7.6751,   2.7032,  ...,   0.1711,   6.5936,  -9.1927],\n",
      "          [  3.5807,  10.7099,   2.2698,  ...,   4.3635,   0.5125,  -3.3419],\n",
      "          ...,\n",
      "          [  3.8529,  -6.7545,  -2.0444,  ...,  -1.4660,  10.0939,  -7.8701],\n",
      "          [ -1.2602,   0.6226,  -4.5501,  ...,   6.5817,   6.6146,   5.5668],\n",
      "          [ -1.7386,  -1.1721,   2.6398,  ...,   6.2234,   6.5880,   5.7800]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]]],\n",
      "\n",
      "\n",
      "        [[[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "         [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "          [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "          [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "          ...,\n",
      "          [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "          [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "          [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]]]])\n",
      "Shape of Tensor:  torch.Size([3, 10, 30, 100])\n"
     ]
    }
   ],
   "source": [
    "indexed_tensor = product[long_tensor]\n",
    "print('Indexed Tensor: \\n' , indexed_tensor)\n",
    "\n",
    "print('Shape of Tensor: ' , indexed_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Use  torch.mean  to average across the last dimension in the tensor from step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9780,  0.1409,  0.0164,  0.6696, -0.0305,  0.8646, -0.9373,\n",
      "           0.3716, -1.9576, -0.4617, -0.1304,  0.3595, -0.0311, -0.0050,\n",
      "           0.3988, -0.5350, -0.4537, -0.3252, -0.5399, -0.8216, -0.1944,\n",
      "          -0.3944,  0.1982,  0.3858, -0.0894,  0.0317, -1.2584, -0.1178,\n",
      "           0.7664,  0.0586],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067]],\n",
      "\n",
      "        [[ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.2249, -0.8812,  0.6083,  0.6058,  0.6880, -0.9282,  0.4375,\n",
      "          -0.2376,  0.0710, -0.2554, -0.1710, -0.1375,  0.4609,  0.3370,\n",
      "          -0.0385, -0.0138,  0.8399, -0.3713, -0.4794,  0.1453, -0.3198,\n",
      "          -0.8334, -0.1936,  0.2483,  0.2936, -0.5223, -0.2766, -0.3383,\n",
      "          -0.5008, -0.1701],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067]],\n",
      "\n",
      "        [[ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [-0.4344, -0.8409, -0.5016,  0.3202,  0.4835, -0.3059, -0.2600,\n",
      "          -0.3579, -0.6635, -0.9374,  0.1386,  0.2069,  0.6237,  0.3788,\n",
      "           0.3511,  0.4541,  0.9487, -0.2848, -0.5412, -0.9560,  0.4755,\n",
      "           0.8696, -0.8124, -0.3233,  0.3276,  0.1670, -0.4078, -0.2322,\n",
      "           0.3048,  0.0450],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067],\n",
      "         [ 0.3057, -0.3834, -0.0205, -0.3193,  0.5104,  0.8959, -0.2007,\n",
      "          -0.2290,  0.0724, -0.4566, -0.0673, -0.4029,  0.2401, -0.6753,\n",
      "          -0.8818,  0.0737,  1.0051,  0.5807,  0.3742, -0.9119, -0.2587,\n",
      "          -0.1744, -0.6148, -0.2487, -0.0544, -0.0291, -0.3065, -0.3699,\n",
      "           0.5765,  0.4067]]])\n",
      "Shape of Tensor:  torch.Size([3, 10, 30])\n"
     ]
    }
   ],
   "source": [
    "mean_tensor = torch.mean(indexed_tensor, dim = 3)\n",
    "print(mean_tensor)\n",
    "\n",
    "print('Shape of Tensor: ' , mean_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Redo step 2. on the GPU and compare results from step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product of tensor_a and tensor_b on GPU: \n",
      " tensor([[[  0.7419,  -6.8593,  -5.6530,  ...,  -2.0349,   2.4414,   2.7202],\n",
      "         [ -2.0525,  -1.0605,   1.5309,  ...,  -2.1761,  -9.4649,   5.6621],\n",
      "         [  1.0493,   4.3634,   5.6647,  ...,   0.6152,  -1.0595,  -1.3253],\n",
      "         ...,\n",
      "         [ -2.0524,  -0.0474,  10.1518,  ...,  -6.3781,  -0.3214,   4.9168],\n",
      "         [  0.8337,   4.8886,  -4.8482,  ...,   1.5900,  -1.4781, -16.4335],\n",
      "         [  6.8869,  -2.4298,   6.2692,  ...,  -7.8960,  -8.9709,  13.8102]],\n",
      "\n",
      "        [[  3.0969,  -2.9833,  13.2520,  ...,   1.7131,   4.2529,   3.6317],\n",
      "         [-14.9454,   3.4417,   8.3670,  ..., -13.2908,  -3.4036,   3.4407],\n",
      "         [ -1.1023,  -2.3452,  -9.4379,  ...,   8.2076,   0.0621,   6.5526],\n",
      "         ...,\n",
      "         [  1.0201,  -2.7870,   0.8705,  ...,  -8.0924,   7.7629,   2.7560],\n",
      "         [  0.2498,   0.6520,   4.8183,  ...,   9.8432,   0.0732,  -4.6423],\n",
      "         [ -0.6132,   6.2754,  -4.9302,  ...,  10.5994,   7.3176,  -0.1947]],\n",
      "\n",
      "        [[  6.1546,   0.7146,   2.1322,  ...,  -4.5322,  -0.1707,  -4.5282],\n",
      "         [  5.9549, -10.3146,  -1.0091,  ...,   1.8014,   5.4770,  -2.0132],\n",
      "         [  1.0229,  -2.9217,   6.4467,  ...,   7.3697,  -1.7195,  12.6359],\n",
      "         ...,\n",
      "         [ -6.4925,  -3.8809,  -2.3571,  ...,  -3.6958,   7.8894,  -8.6069],\n",
      "         [  3.0474,  -2.9584,   1.4904,  ...,   1.5481,   7.2212, -10.0925],\n",
      "         [  0.0166,  10.6724,   0.1993,  ...,  11.7513,   1.0871,   1.5053]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  2.6810,  -4.3125,  -1.8347,  ..., -12.3051,   2.4593,  -4.0132],\n",
      "         [ -0.4259,  -0.5535,  -3.3544,  ...,   1.7058,  -3.8773,  -5.1241],\n",
      "         [-11.0149,  -3.3008,  -3.6872,  ...,   1.6458,   8.3347,  -3.1148],\n",
      "         ...,\n",
      "         [  3.6411, -13.9457,   2.9425,  ..., -11.4886,  -8.2979,  -5.2767],\n",
      "         [ -1.3502,   6.5703,  11.5629,  ...,  -1.4349,  -1.2074,   6.3165],\n",
      "         [  2.6934,   2.0616,  -0.6348,  ...,  -3.7450,   0.5671,   0.8650]],\n",
      "\n",
      "        [[  2.7736,  -1.4151,   4.0755,  ..., -11.7215,  -4.3883,   4.5976],\n",
      "         [  4.5642,  -1.2270,   7.2177,  ...,   1.6591,  -0.7404,   1.1020],\n",
      "         [ -7.7290,   4.4398,   3.1149,  ...,   5.1482,   2.5751,   9.8370],\n",
      "         ...,\n",
      "         [  6.3003,  -0.6190,  -5.1802,  ...,   4.2852,  -1.2074,   7.4648],\n",
      "         [ -2.9038,  -0.8584,  -5.1471,  ...,   1.2670,  -0.4973,  -0.9703],\n",
      "         [  1.8961,  -2.9697,   9.3500,  ...,  -7.1284,  -1.8419,  -0.6842]],\n",
      "\n",
      "        [[-10.0955,   3.9633,  -8.4298,  ...,  -2.9574, -12.3479,  11.4634],\n",
      "         [  5.7856,   4.0575,  -1.1645,  ...,  -4.4277,  -0.2743,  -5.9354],\n",
      "         [ -6.6147,   5.3965,   2.0963,  ...,   3.1064,  -1.1301,  -0.8767],\n",
      "         ...,\n",
      "         [  1.9751,   6.1068,   6.5911,  ...,  -9.8484,  -1.8429,  -7.2884],\n",
      "         [ -2.4903,   0.6457,  -2.0200,  ..., -11.5766,  -3.9897,  -4.1240],\n",
      "         [  0.2536,  -0.3082,  -3.5614,  ...,   8.9747,   4.6388,   0.4851]]])\n",
      "Shape of Tensor:  torch.Size([29, 30, 100])\n"
     ]
    }
   ],
   "source": [
    "tensor_a_cuda = tensor_a.to(device = device)\n",
    "tensor_b_cuda = tensor_b.to(device = device)\n",
    "product_gpu = torch.matmul(tensor_a, tensor_b)\n",
    "print('Product of tensor_a and tensor_b on GPU: \\n' , product_gpu)\n",
    "\n",
    "print('Shape of Tensor: ' , product_gpu.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Write a pure PyTorch program to compute the value of  up to 4 decimal places without using the square root or other math functions from any of the libraries. \n",
    "### Hint: Notice that the answer is the (positive) root of the equation, $$𝑥^2 −2 = 0$$ \n",
    "### To find the root, you might want to use \"Newton's Method\": $$𝑥_{𝑛+1} = 𝑥_{𝑛} − \\frac{𝑓(𝑥)}{𝑓′(𝑥)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fail-fast prototyping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building neural networks, you want things to either work or fail fast. Long iteration loops are \n",
    "the worst enemy of a machine learning practitioner. \\\n",
    "For e.g., while writing code, you might want to incrementally test your code by doing something \n",
    "like this:\n",
    "\n",
    "batch_size = 32 \\\n",
    "num_features = 512 \\\n",
    "embedding_size = 16\n",
    "\n",
    "\\# construct a dummy input \\\n",
    "x = torch.randn(batch_size, num_features)\n",
    "\n",
    "\\# we want to project the input to embedding_size \\\n",
    "fc = torch.nn.Linear(num_features, embedding_size)\n",
    "\n",
    "\\# test if that works \\\n",
    "print(fc(x).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fail-fast exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Glove](https://nlp.stanford.edu/projects/glove/) has 300 dimension embeddings. Design an nn.Module that takes a sentence of max_len words, tokenizes words by spaces, represents the sentence by averaging the glove embeddings of constituent words. What is the shape of the resulting sentence embedding? When you implement this, you will need to make some assumptions. What are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2196017 words present in GloVe\n",
      "tensor([ 2.7204e-01, -6.2030e-02, -1.8840e-01,  2.3225e-02, -1.8158e-02,\n",
      "         6.7192e-03, -1.3877e-01,  1.7708e-01,  1.7709e-01,  2.5882e+00,\n",
      "        -3.5179e-01, -1.7312e-01,  4.3285e-01, -1.0708e-01,  1.5006e-01,\n",
      "        -1.9982e-01, -1.9093e-01,  1.1871e+00, -1.6207e-01, -2.3538e-01,\n",
      "         3.6640e-03, -1.9156e-01, -8.5662e-02,  3.9199e-02, -6.6449e-02,\n",
      "        -4.2090e-02, -1.9122e-01,  1.1679e-02, -3.7138e-01,  2.1886e-01,\n",
      "         1.1423e-03,  4.3190e-01, -1.4205e-01,  3.8059e-01,  3.0654e-01,\n",
      "         2.0167e-02, -1.8316e-01, -6.5186e-03, -8.0549e-03, -1.2063e-01,\n",
      "         2.7507e-02,  2.9839e-01, -2.2896e-01, -2.2882e-01,  1.4671e-01,\n",
      "        -7.6301e-02, -1.2680e-01, -6.6651e-03, -5.2795e-02,  1.4258e-01,\n",
      "         1.5610e-01,  5.5510e-02, -1.6149e-01,  9.6290e-02, -7.6533e-02,\n",
      "        -4.9971e-02, -1.0195e-02, -4.7641e-02, -1.6679e-01, -2.3940e-01,\n",
      "         5.0141e-03, -4.9175e-02,  1.3338e-02,  4.1923e-01, -1.0104e-01,\n",
      "         1.5111e-02, -7.7706e-02, -1.3471e-01,  1.1900e-01,  1.0802e-01,\n",
      "         2.1061e-01, -5.1904e-02,  1.8527e-01,  1.7856e-01,  4.1293e-02,\n",
      "        -1.4385e-02, -8.2567e-02, -3.5483e-02, -7.6173e-02, -4.5367e-02,\n",
      "         8.9281e-02,  3.3672e-01, -2.2099e-01, -6.7275e-03,  2.3983e-01,\n",
      "        -2.3147e-01, -8.8592e-01,  9.1297e-02, -1.2123e-02,  1.3233e-02,\n",
      "        -2.5799e-01, -2.9720e-02,  1.6754e-02,  1.3690e-02,  3.2377e-01,\n",
      "         3.9546e-02,  4.2114e-02, -8.8243e-02,  3.0318e-01,  8.7747e-02,\n",
      "         1.6346e-01, -4.0485e-01, -4.3845e-02, -4.0697e-02,  2.0936e-01,\n",
      "        -7.7795e-01,  2.9970e-01,  2.3340e-01,  1.4891e-01, -3.9037e-01,\n",
      "        -5.3086e-02,  6.2922e-02,  6.5663e-02, -1.3906e-01,  9.4193e-02,\n",
      "         1.0344e-01, -2.7970e-01,  2.8905e-01, -3.2161e-01,  2.0687e-02,\n",
      "         6.3254e-02, -2.3257e-01, -4.3520e-01, -1.7049e-02, -3.2744e-01,\n",
      "        -4.7064e-02, -7.5149e-02, -1.8788e-01, -1.5017e-02,  2.9342e-02,\n",
      "        -3.5270e-01, -4.4278e-02, -1.3507e-01, -1.1644e-01, -1.0430e-01,\n",
      "         1.3920e-01,  3.9199e-03,  3.7603e-01,  6.7217e-02, -3.7992e-01,\n",
      "        -1.1241e+00, -5.7357e-02, -1.6826e-01,  3.9410e-02,  2.6040e-01,\n",
      "        -2.3866e-02,  1.7963e-01,  1.3553e-01,  2.1390e-01,  5.2633e-02,\n",
      "        -2.5033e-01, -1.1307e-01,  2.2234e-01,  6.6597e-02, -1.1161e-01,\n",
      "         6.2438e-02, -2.7972e-01,  1.9878e-01, -3.6262e-01, -1.0006e-05,\n",
      "        -1.7262e-01,  2.9166e-01, -1.5723e-01,  5.4295e-02,  6.1010e-02,\n",
      "        -3.9165e-01,  2.7660e-01,  5.7816e-02,  3.9709e-01,  2.5229e-02,\n",
      "         2.4672e-01, -8.9050e-02,  1.5683e-01, -2.0960e-01, -2.2196e-01,\n",
      "         5.2394e-02, -1.1360e-02,  5.0417e-02, -1.4023e-01, -4.2825e-02,\n",
      "        -3.1931e-02, -2.1336e-01, -2.0402e-01, -2.3272e-01,  7.4490e-02,\n",
      "         8.8202e-02, -1.1063e-01, -3.3526e-01, -1.4028e-02, -2.9429e-01,\n",
      "        -8.6911e-02, -1.3210e-01, -4.3616e-01,  2.0513e-01,  7.9362e-03,\n",
      "         4.8505e-01,  6.4237e-02,  1.4261e-01, -4.3711e-01,  1.2783e-01,\n",
      "        -1.3111e-01,  2.4673e-01, -2.7496e-01,  1.5896e-01,  4.3314e-01,\n",
      "         9.0286e-02,  2.4662e-01,  6.6463e-02, -2.0099e-01,  1.1010e-01,\n",
      "         3.6440e-02,  1.7359e-01, -1.5689e-01, -8.6328e-02, -1.7316e-01,\n",
      "         3.6975e-01, -4.0317e-01, -6.4814e-02, -3.4166e-02, -1.3773e-02,\n",
      "         6.2854e-02, -1.7183e-01, -1.2366e-01, -3.4663e-02, -2.2793e-01,\n",
      "        -2.3172e-01,  2.3900e-01,  2.7473e-01,  1.5332e-01,  1.0661e-01,\n",
      "        -6.0982e-02, -2.4805e-02, -1.3478e-01,  1.7932e-01, -3.7374e-01,\n",
      "        -2.8930e-02, -1.1142e-01, -8.3890e-02, -5.5932e-02,  6.8039e-02,\n",
      "        -1.0783e-01,  1.4650e-01,  9.4617e-02, -8.4554e-02,  6.7429e-02,\n",
      "        -3.2910e-01,  3.4082e-02, -1.6747e-01, -2.5997e-01, -2.2917e-01,\n",
      "         2.0159e-02, -2.7580e-02,  1.6136e-01, -1.8538e-01,  3.7665e-02,\n",
      "         5.7603e-01,  2.0684e-01,  2.7941e-01,  1.6477e-01, -1.8769e-02,\n",
      "         1.2062e-01,  6.9648e-02,  5.9022e-02, -2.3154e-01,  2.4095e-01,\n",
      "        -3.4710e-01,  4.8540e-02, -5.6502e-02,  4.1566e-01, -4.3194e-01,\n",
      "         4.8230e-01, -5.1759e-02, -2.7285e-01, -2.5893e-01,  1.6555e-01,\n",
      "        -1.8310e-01, -6.7340e-02,  4.2457e-01,  1.0346e-02,  1.4237e-01,\n",
      "         2.5939e-01,  1.7123e-01, -1.3821e-01, -6.6846e-02,  1.5981e-02,\n",
      "        -3.0193e-01,  4.3579e-02, -4.3102e-02,  3.5025e-01, -1.9681e-01,\n",
      "        -4.2810e-01,  1.6899e-01,  2.2511e-01, -2.8557e-01, -1.0280e-01,\n",
      "        -1.8168e-02,  1.1407e-01,  1.3015e-01, -1.8317e-01,  1.3230e-01])\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe Embeddings\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "GLOVE_DIM = 300\n",
    "glove = GloVe(name = '840B', dim = GLOVE_DIM)\n",
    "\n",
    "print(f'Loaded {len(glove.itos)} words present in GloVe')\n",
    "\n",
    "# Get Embedding for given word\n",
    "def get_word_embedding(word):\n",
    "    return glove.vectors[glove.stoi[word]]\n",
    "\n",
    "print(get_word_embedding('the'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b37beb76676c8b0643f5764b5c5ae0ddf876ecbab29b433e279cae2d82963c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
