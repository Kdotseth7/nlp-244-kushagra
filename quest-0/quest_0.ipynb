{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "0.14.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set device as GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    dev = 'mps'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)    \n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch warmup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use torch.randn to create two tensors of size (29, 30, 32) and (32, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of Size (29, 30, 32): \n",
      " tensor([[[ 2.4883, -0.9607, -0.4936,  ...,  0.6693, -0.7385, -0.4228],\n",
      "         [-1.3166, -1.2814, -0.5079,  ...,  0.0275, -0.6966, -0.0137],\n",
      "         [ 1.4568,  0.8041,  0.6488,  ...,  0.1120,  0.4691, -0.6442],\n",
      "         ...,\n",
      "         [ 0.3687, -0.3073, -0.4400,  ...,  1.5777, -0.7677, -3.1722],\n",
      "         [ 0.1493,  0.4918, -0.0713,  ..., -0.1203,  1.4416, -0.6047],\n",
      "         [ 0.1150,  0.1204,  0.8325,  ...,  0.2933,  0.0103,  1.3892]],\n",
      "\n",
      "        [[-0.2833,  2.4623,  0.4313,  ..., -0.3744,  1.3384,  0.3361],\n",
      "         [ 0.6341, -2.5899, -1.5346,  ...,  1.8833,  1.5330,  2.8123],\n",
      "         [ 0.9887,  0.0256, -0.1502,  ..., -0.3124, -0.2741, -1.9220],\n",
      "         ...,\n",
      "         [-0.3817,  1.2395,  0.2199,  ..., -0.4855,  0.6763,  0.9322],\n",
      "         [ 0.7887,  0.5858, -0.0191,  ...,  1.0338, -0.6456,  0.2856],\n",
      "         [ 0.0657,  0.5614, -0.7906,  ...,  0.2635, -0.9823, -1.6203]],\n",
      "\n",
      "        [[-0.4817,  0.1315, -1.3201,  ...,  0.8710,  0.9048, -1.3712],\n",
      "         [ 0.4683, -1.2640, -0.4589,  ..., -0.2671, -0.9958, -1.8059],\n",
      "         [-0.0041,  0.5784,  0.6758,  ..., -0.6231,  2.2426,  1.7402],\n",
      "         ...,\n",
      "         [ 1.0027, -0.3390,  0.3072,  ...,  0.9627, -0.5447, -0.8304],\n",
      "         [ 0.1741, -0.7261, -1.0001,  ..., -0.6963, -0.9231, -1.2164],\n",
      "         [ 0.5564,  1.1764,  0.2066,  ...,  1.6669, -1.2439, -0.8614]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6718, -0.0318, -0.7932,  ...,  1.8871, -1.4116,  0.5886],\n",
      "         [ 1.2584,  1.4729, -0.4301,  ...,  1.1514, -0.6600,  0.2060],\n",
      "         [ 0.0714, -1.2712, -0.3312,  ...,  0.2829, -1.6457,  1.0698],\n",
      "         ...,\n",
      "         [-0.2478, -1.1327,  1.0281,  ..., -1.2553, -1.4438,  1.5366],\n",
      "         [ 0.0120,  0.8034, -0.2253,  ..., -0.0862, -1.3967,  0.2009],\n",
      "         [-0.5715,  0.8526, -0.5702,  ...,  0.3797,  0.2165, -0.7685]],\n",
      "\n",
      "        [[ 1.3267,  0.6122, -0.9812,  ..., -0.0094, -1.3978, -0.1495],\n",
      "         [ 0.3265, -1.7688,  0.9474,  ..., -0.6038,  0.4226,  0.9014],\n",
      "         [-1.1336,  0.0667, -1.6568,  ..., -1.6660,  0.3859, -0.8749],\n",
      "         ...,\n",
      "         [-0.0167,  0.4399, -0.6325,  ...,  0.2427,  1.1247, -0.1819],\n",
      "         [-0.6593,  2.0385, -1.1989,  ...,  0.9004,  0.9822,  0.6201],\n",
      "         [ 0.7480,  0.8673,  0.7471,  ...,  0.5069,  0.9630,  0.4663]],\n",
      "\n",
      "        [[ 1.7994, -0.8050,  1.2900,  ...,  0.5085, -1.8891, -1.4505],\n",
      "         [-2.1340, -1.5581,  0.3395,  ..., -0.6578,  0.0597, -1.4509],\n",
      "         [ 0.4029, -2.3962, -0.4786,  ..., -0.6102,  0.6300, -0.5502],\n",
      "         ...,\n",
      "         [ 0.7752, -1.2950, -1.2990,  ..., -0.4063,  0.5670,  0.6089],\n",
      "         [ 1.0568, -0.5919,  0.0622,  ...,  0.0354, -0.2069, -0.6192],\n",
      "         [-1.3042, -0.8627, -0.4069,  ...,  0.7071,  1.5918,  0.2411]]])\n",
      "Tensor of Size (32, 100): \n",
      " tensor([[-1.6497,  0.1839,  0.4831,  ...,  1.2050,  0.1469,  0.0148],\n",
      "        [ 1.1806, -1.1955, -0.9156,  ...,  0.0952, -0.0274,  0.9344],\n",
      "        [-0.6497, -0.7459, -0.2343,  ...,  1.0270, -0.1453,  1.1346],\n",
      "        ...,\n",
      "        [ 0.8655, -0.3544,  0.4475,  ..., -0.6998,  1.5646,  0.8599],\n",
      "        [ 0.2189, -0.4093, -0.5043,  ..., -0.8470, -0.1216,  0.4031],\n",
      "        [-1.0637,  1.4700,  1.4923,  ..., -0.2871,  0.4489,  0.8114]])\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randn(29, 30, 32)\n",
    "print('Tensor of Size (29, 30, 32): \\n' , tensor_a)\n",
    "\n",
    "tensor_b = torch.randn(32, 100)\n",
    "print('Tensor of Size (32, 100): \\n' , tensor_b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use  torch.matmul  to matrix multiply the two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product of tensor_a and tensor_b: \n",
      " tensor([[[ 10.6310,  -3.5012,  -0.2206,  ...,   9.4495,  13.3306,   8.3598],\n",
      "         [ -5.7695,  -3.4139,   0.3206,  ...,  -2.8361,  -4.5913,  -6.8342],\n",
      "         [ -3.9164,  -2.8580,   2.4313,  ...,  -4.2417,  -4.1108,   2.8881],\n",
      "         ...,\n",
      "         [  1.2043,   2.1710,  -0.2518,  ...,  -3.4719,  -5.5821,   0.8495],\n",
      "         [  0.2801,   1.7620,  -3.0831,  ...,  -4.7040,  -1.3947,   0.6950],\n",
      "         [ -6.4814,  -5.7364,   7.5082,  ...,  -7.7107,   1.4880,   2.2745]],\n",
      "\n",
      "        [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "         [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "         [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "         ...,\n",
      "         [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "         [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "         [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "        [[  6.5144,  -5.0366,   7.4834,  ...,   3.8429,   2.2695,  -0.7630],\n",
      "         [ -8.4859,  -6.7342,  -0.2137,  ...,  -3.6924,   6.2722,  -2.2939],\n",
      "         [ -3.2167,   3.1696,  -7.2846,  ...,   1.9399,  -4.1745,  -1.4905],\n",
      "         ...,\n",
      "         [  9.5965,  -0.8727,  -0.5326,  ...,   0.7845,  -1.8750,   7.3734],\n",
      "         [ -3.8006,  -0.9587,  13.1253,  ...,  -0.7203,   1.2108,  -3.4721],\n",
      "         [ -4.2917,  -0.2778,   7.3940,  ...,  -5.7005,   5.7263,   2.9652]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  1.2714,  14.7620,  -5.7455,  ...,   8.9089,   1.0362,   1.0137],\n",
      "         [  8.8078,  -1.1073,   0.2645,  ...,   6.3896,  -4.6478,  -3.6416],\n",
      "         [ -2.1712,  -4.8174,   3.9219,  ...,   2.7737,   5.9760,  -7.4054],\n",
      "         ...,\n",
      "         [-11.2472,   2.2232,   1.9609,  ...,   9.7487,   4.4935,  -7.1025],\n",
      "         [ -1.5139,  -1.4225,   2.6128,  ...,   9.1338,   4.2252,   0.5267],\n",
      "         [  9.8435,  -6.3260,  -3.1707,  ...,   3.8220,   2.5100,   2.0083]],\n",
      "\n",
      "        [[  3.0478,   5.5787,  -5.9161,  ...,  16.0840,  -3.8409,  -0.2456],\n",
      "         [ -5.6851,  14.2313,   1.0429,  ...,  -5.7644,   2.0863,   5.2115],\n",
      "         [ -1.6326,  -2.6154,   1.0637,  ...,   3.8644,  -6.5018, -10.2203],\n",
      "         ...,\n",
      "         [ 11.2611,  -1.3466,  -3.1440,  ...,   5.8430,  17.1581,  -0.5921],\n",
      "         [  5.0990,  -1.9694,  -6.2408,  ...,  -4.1114,   3.4708,   2.5668],\n",
      "         [  7.7660,   0.4631,  -0.0747,  ...,   5.6320,   7.1859,  10.9072]],\n",
      "\n",
      "        [[ -3.8651,   2.8302,  -3.5758,  ...,   2.7796,   1.0496,  -0.4569],\n",
      "         [  6.2057,  -2.7281,   2.9944,  ...,   2.7112,   1.3277,  -3.5395],\n",
      "         [ -6.0674,   2.5935,   1.0015,  ...,  -6.2152,   9.2651,  -6.5233],\n",
      "         ...,\n",
      "         [  3.2077,   1.0940,   6.3089,  ...,   4.1105,   2.1921,  -9.3530],\n",
      "         [ -8.8262,  -0.8757,  -0.8506,  ...,   1.2761,  -1.2785,  -0.9866],\n",
      "         [  2.5664,   3.6168,  -0.5131,  ...,   2.3085,   1.1554, -13.7889]]])\n",
      "Shape of Tensor:  torch.Size([29, 30, 100])\n"
     ]
    }
   ],
   "source": [
    "product = torch.matmul(tensor_a, \n",
    "                       tensor_b)\n",
    "print('Product of tensor_a and tensor_b: \\n' , product)\n",
    "\n",
    "print('Shape of Tensor: ' , product.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the difference between torch.matmul , torch.mm , torch.bmm , and torch.einsum , and the @ operator?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. torch.matmul() -> It is a matrix multiplication function that can handle broadcasting, it can be used to perform matrix multiplication between two tensors of any shape. The function will automatically broadcast the smaller tensor to match the shape of the larger tensor, and then perform the matrix multiplication.\n",
    "2. torch.mm() -> It is also a matrix multiplication function, but it is a lower level function that does not handle broadcasting. It can only be used to perform matrix multiplication between two tensors with the same number of dimensions and the last two dimensions should have the same size. It is faster than torch.matmul since it avoids broadcasting.\n",
    "3. torch.bmm() -> It is used for batch matrix multiplication, it accepts three tensors of shapes (batch size, n, m), (batch size, m, p) and (batch size, n, p) to perform matrix multiplication on the last two dimensions of the input tensors.\n",
    "4. torch.einsum() -> It is a more flexible function than the others and allows you to specify the indices of the tensors that you want to contract, it can also be used for many other operations like dot product, outer product, and tensor transpose.\n",
    "5. @ operator -> It is a shorthand for the torch.matmul() function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use torch.sum on the resulting tensor, passing the optional argument of dim=1 to sum across the 1st dimension. Before you run this, can you predict the size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Tensor across 1st Dimension: \n",
      " tensor([[-26.3680,  -8.1909,  12.9245,  ..., -27.4859,  31.5785,   9.4467],\n",
      "        [ -7.5412, -15.4592,  55.8832,  ..., -22.3710,  42.2481,  11.7929],\n",
      "        [ 40.2438,  31.4988,   7.6273,  ...,  24.0534,  26.2030, -29.9862],\n",
      "        ...,\n",
      "        [ 28.6942,   6.3963,  46.8983,  ...,  71.9117,  -0.1161, -34.1402],\n",
      "        [ 31.7517,  45.7850,   3.1688,  ...,  70.1577,  26.3011,  11.8690],\n",
      "        [ 12.1463,  -6.6169,  -3.0134,  ...,  13.9262,  28.7455, -54.7362]])\n",
      "Shape of Tensor:  torch.Size([29, 100])\n"
     ]
    }
   ],
   "source": [
    "tensor_sum = torch.sum(product, \n",
    "                       dim = 1)\n",
    "print('Sum of Tensor across 1st Dimension: \\n' , tensor_sum)\n",
    "\n",
    "print('Shape of Tensor: ' , tensor_sum.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a new long tensor of size  (3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Tensor: \n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Updated Long Tensor: \n",
      " tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 4, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 6, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "long_tensor = torch.ones((3, 10), \n",
    "                         dtype = torch.long)\n",
    "print('Long Tensor: \\n' , long_tensor)\n",
    "\n",
    "long_tensor[0, 0] = 2\n",
    "long_tensor[1, 2] = 4\n",
    "long_tensor[2, 4] = 6\n",
    "\n",
    "print('Updated Long Tensor: \\n' , long_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use this new long tensor to index into the tensor from step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed Tensor: \n",
      " tensor([[[[  6.5144,  -5.0366,   7.4834,  ...,   3.8429,   2.2695,  -0.7630],\n",
      "          [ -8.4859,  -6.7342,  -0.2137,  ...,  -3.6924,   6.2722,  -2.2939],\n",
      "          [ -3.2167,   3.1696,  -7.2846,  ...,   1.9399,  -4.1745,  -1.4905],\n",
      "          ...,\n",
      "          [  9.5965,  -0.8727,  -0.5326,  ...,   0.7845,  -1.8750,   7.3734],\n",
      "          [ -3.8006,  -0.9587,  13.1253,  ...,  -0.7203,   1.2108,  -3.4721],\n",
      "          [ -4.2917,  -0.2778,   7.3940,  ...,  -5.7005,   5.7263,   2.9652]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]]],\n",
      "\n",
      "\n",
      "        [[[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  4.2316,   9.4979,  -7.9949,  ...,  -3.3079,   7.0098,  10.5983],\n",
      "          [ -3.6499,  -0.8249,   9.9598,  ...,  -2.7222,   4.4877,   1.1165],\n",
      "          [  5.7546,   0.9336,  -6.6953,  ...,  -3.2647,  -2.8155,   3.3887],\n",
      "          ...,\n",
      "          [ -4.1564,  -3.6446,   6.0897,  ...,  -4.9530,   2.3255,   0.6781],\n",
      "          [ -4.6250,  -8.9788,  -4.3033,  ...,  -8.1147,  -3.3082,   0.8287],\n",
      "          [  0.9226,  -6.2269,   0.3767,  ...,   7.3595,  -1.9230,   0.9523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]]],\n",
      "\n",
      "\n",
      "        [[[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "         [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "          [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "          [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "          ...,\n",
      "          [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "          [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "          [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]]]])\n",
      "Shape of Tensor:  torch.Size([3, 10, 30, 100])\n"
     ]
    }
   ],
   "source": [
    "indexed_tensor = product[long_tensor]\n",
    "print('Indexed Tensor: \\n' , indexed_tensor)\n",
    "\n",
    "print('Shape of Tensor: ' , indexed_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Use  torch.mean  to average across the last dimension in the tensor from step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.7892e-02,  5.0581e-01, -3.4461e-02, -4.1773e-01,  1.7341e-02,\n",
      "          -4.7851e-01,  6.9303e-01, -1.7999e-01, -7.4158e-02,  4.0920e-01,\n",
      "           5.1396e-01, -1.2904e-01, -3.7786e-01, -3.6777e-02,  1.2503e+00,\n",
      "           5.4853e-01,  5.3842e-01,  3.6802e-01, -7.5418e-02, -3.9743e-01,\n",
      "          -7.2443e-01,  3.2765e-02, -2.1954e-01,  2.0872e-01, -7.8701e-01,\n",
      "           1.3227e+00,  2.1916e-01,  6.9837e-02,  2.1579e-01,  1.3233e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01]],\n",
      "\n",
      "        [[ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [-6.0447e-01,  5.8673e-02, -2.9488e-01,  7.7714e-01, -1.5729e-01,\n",
      "           1.5014e-01, -1.2229e-01, -5.7418e-01,  3.3690e-01,  3.2516e-01,\n",
      "          -4.5117e-01,  6.3982e-02,  4.4131e-01,  3.9107e-01,  3.5250e-02,\n",
      "          -6.1167e-01, -1.6268e+00,  2.7248e-01,  3.8716e-01, -1.6287e-01,\n",
      "          -1.3652e-01,  8.6099e-01,  4.9854e-02,  2.9558e-01,  3.5936e-01,\n",
      "           1.7772e-01, -3.9391e-01, -2.3378e-01, -3.5788e-01,  1.1066e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01]],\n",
      "\n",
      "        [[ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 1.6725e-01,  4.0078e-01, -7.2186e-02, -7.5542e-01, -1.4148e+00,\n",
      "          -3.8439e-01,  2.9080e-01, -2.7210e-01,  1.9111e-01, -5.5628e-01,\n",
      "           4.8529e-01, -1.0814e-01, -7.5440e-03, -1.4838e-01,  3.7917e-02,\n",
      "           7.0451e-01,  5.6948e-01,  1.0263e-01,  9.0407e-01, -2.5157e-02,\n",
      "           6.3259e-01,  1.9209e-01, -2.5494e-01,  6.3779e-01,  7.0430e-01,\n",
      "           9.1176e-02, -6.3535e-01,  8.1605e-01, -2.5078e-01, -3.1608e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01],\n",
      "         [ 6.9553e-01, -9.8286e-01, -1.3238e-02, -4.1150e-02, -4.8392e-02,\n",
      "           1.1633e+00, -7.0964e-01, -7.5471e-02,  1.0129e-01, -2.7180e-01,\n",
      "          -1.4452e-02,  3.4041e-01,  3.5615e-01,  4.5030e-01,  3.3111e-01,\n",
      "          -2.7080e-02,  7.3014e-01,  7.3225e-02, -4.3879e-01, -1.2075e+00,\n",
      "          -4.5055e-02,  8.3584e-02, -2.8191e-05, -2.7348e-01,  4.2732e-01,\n",
      "          -2.3573e-01,  4.3454e-01,  2.8898e-01,  2.2725e-01,  9.5347e-01]]])\n",
      "Shape of Tensor:  torch.Size([3, 10, 30])\n"
     ]
    }
   ],
   "source": [
    "mean_tensor = torch.mean(indexed_tensor, \n",
    "                         dim = 3)\n",
    "print(mean_tensor)\n",
    "\n",
    "print('Shape of Tensor: ' , mean_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Redo step 2. on the GPU and compare results from step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product of tensor_a and tensor_b on GPU: \n",
      " tensor([[[ 10.6310,  -3.5012,  -0.2206,  ...,   9.4495,  13.3306,   8.3598],\n",
      "         [ -5.7695,  -3.4139,   0.3206,  ...,  -2.8361,  -4.5913,  -6.8342],\n",
      "         [ -3.9164,  -2.8580,   2.4313,  ...,  -4.2417,  -4.1108,   2.8881],\n",
      "         ...,\n",
      "         [  1.2043,   2.1710,  -0.2518,  ...,  -3.4719,  -5.5821,   0.8495],\n",
      "         [  0.2801,   1.7620,  -3.0831,  ...,  -4.7040,  -1.3947,   0.6950],\n",
      "         [ -6.4814,  -5.7364,   7.5082,  ...,  -7.7107,   1.4880,   2.2745]],\n",
      "\n",
      "        [[  2.5742,  -2.1590,  -0.8438,  ...,   6.8380,  -1.2750,  -0.7221],\n",
      "         [-13.9902,   3.1549,   8.2805,  ...,  -8.4492,  -1.1996,  -1.7942],\n",
      "         [ -2.3876,  -7.6067,   1.1881,  ...,   6.5266,   6.2222,  -7.3543],\n",
      "         ...,\n",
      "         [ -1.0327,   0.0378,   4.1401,  ...,  -3.9587,   0.1316,   3.5204],\n",
      "         [ -6.3405,   8.9789,   7.8754,  ...,  -9.0973,  -0.6199,   0.8649],\n",
      "         [  4.1925,  -0.6651,   2.5484,  ...,   1.6287,   3.9758,  -4.6517]],\n",
      "\n",
      "        [[  6.5144,  -5.0366,   7.4834,  ...,   3.8429,   2.2695,  -0.7630],\n",
      "         [ -8.4859,  -6.7342,  -0.2137,  ...,  -3.6924,   6.2722,  -2.2939],\n",
      "         [ -3.2167,   3.1696,  -7.2846,  ...,   1.9399,  -4.1745,  -1.4905],\n",
      "         ...,\n",
      "         [  9.5965,  -0.8727,  -0.5326,  ...,   0.7845,  -1.8750,   7.3734],\n",
      "         [ -3.8006,  -0.9587,  13.1253,  ...,  -0.7203,   1.2108,  -3.4721],\n",
      "         [ -4.2917,  -0.2778,   7.3940,  ...,  -5.7005,   5.7263,   2.9652]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  1.2714,  14.7620,  -5.7455,  ...,   8.9089,   1.0362,   1.0137],\n",
      "         [  8.8078,  -1.1073,   0.2645,  ...,   6.3896,  -4.6478,  -3.6416],\n",
      "         [ -2.1712,  -4.8174,   3.9219,  ...,   2.7737,   5.9760,  -7.4054],\n",
      "         ...,\n",
      "         [-11.2472,   2.2232,   1.9609,  ...,   9.7487,   4.4935,  -7.1025],\n",
      "         [ -1.5139,  -1.4225,   2.6128,  ...,   9.1338,   4.2252,   0.5267],\n",
      "         [  9.8435,  -6.3260,  -3.1707,  ...,   3.8220,   2.5100,   2.0083]],\n",
      "\n",
      "        [[  3.0478,   5.5787,  -5.9161,  ...,  16.0840,  -3.8409,  -0.2456],\n",
      "         [ -5.6851,  14.2313,   1.0429,  ...,  -5.7644,   2.0863,   5.2115],\n",
      "         [ -1.6326,  -2.6154,   1.0637,  ...,   3.8644,  -6.5018, -10.2203],\n",
      "         ...,\n",
      "         [ 11.2611,  -1.3466,  -3.1440,  ...,   5.8430,  17.1581,  -0.5921],\n",
      "         [  5.0990,  -1.9694,  -6.2408,  ...,  -4.1114,   3.4708,   2.5668],\n",
      "         [  7.7660,   0.4631,  -0.0747,  ...,   5.6320,   7.1859,  10.9072]],\n",
      "\n",
      "        [[ -3.8651,   2.8302,  -3.5758,  ...,   2.7796,   1.0496,  -0.4569],\n",
      "         [  6.2057,  -2.7281,   2.9944,  ...,   2.7112,   1.3277,  -3.5395],\n",
      "         [ -6.0674,   2.5935,   1.0015,  ...,  -6.2152,   9.2651,  -6.5233],\n",
      "         ...,\n",
      "         [  3.2077,   1.0940,   6.3089,  ...,   4.1105,   2.1921,  -9.3530],\n",
      "         [ -8.8262,  -0.8757,  -0.8506,  ...,   1.2761,  -1.2785,  -0.9866],\n",
      "         [  2.5664,   3.6168,  -0.5131,  ...,   2.3085,   1.1554, -13.7889]]])\n",
      "Shape of Tensor:  torch.Size([29, 30, 100])\n"
     ]
    }
   ],
   "source": [
    "tensor_a_cuda = tensor_a.to(device = device)\n",
    "tensor_b_cuda = tensor_b.to(device = device)\n",
    "product_gpu = torch.matmul(tensor_a, \n",
    "                           tensor_b)\n",
    "print('Product of tensor_a and tensor_b on GPU: \\n' , product_gpu)\n",
    "\n",
    "print('Shape of Tensor: ' , product_gpu.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Write a pure PyTorch program to compute the value of $\\sqrt{2}$ up to 4 decimal places without using the square root or other math functions from any of the libraries. \n",
    "### Hint: Notice that the answer is the (positive) root of the equation, $$𝑥^2 −2 = 0$$ \n",
    "### To find the root, you might want to use 'Newton's Method': $$𝑥_{𝑛+1} = 𝑥_{𝑛} − \\frac{𝑓(𝑥)}{𝑓′(𝑥)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142\n"
     ]
    }
   ],
   "source": [
    "# Function f(x)\n",
    "def f(x):\n",
    "    return x**2 - 2\n",
    "\n",
    "# Derivative of f(x)\n",
    "def f_prime(x):\n",
    "    return 2*x\n",
    "\n",
    "# Initial Guess = 1.0\n",
    "x = torch.tensor([1.0], \n",
    "                 requires_grad = True)\n",
    "\n",
    "# Number of Iterations\n",
    "n = 10\n",
    "\n",
    "# Newton's Method\n",
    "for i in range(n):\n",
    "    x.data = x - f(x) / f_prime(x)\n",
    "\n",
    "# Print the final approximation to 4 decimal places\n",
    "print(round(x.item(), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fail-fast prototyping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building neural networks, you want things to either work or fail fast. Long iteration loops are \n",
    "the worst enemy of a machine learning practitioner. \\\n",
    "For e.g., while writing code, you might want to incrementally test your code by doing something \n",
    "like this:\n",
    "\n",
    "batch_size = 32 \\\n",
    "num_features = 512 \\\n",
    "embedding_size = 16\n",
    "\n",
    "\\# construct a dummy input \\\n",
    "x = torch.randn(batch_size, num_features)\n",
    "\n",
    "\\# we want to project the input to embedding_size \\\n",
    "fc = torch.nn.Linear(num_features, embedding_size)\n",
    "\n",
    "\\# test if that works \\\n",
    "print(fc(x).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fail-fast exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Glove](https://nlp.stanford.edu/projects/glove/) has 300 dimension embeddings. Design an nn.Module that takes a sentence of max_len words, tokenizes words by spaces, represents the sentence by averaging the glove embeddings of constituent words. What is the shape of the resulting sentence embedding? When you implement this, you will need to make some assumptions. What are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2196017 words present in GloVe\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe Embeddings\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "GLOVE_DIM = 300\n",
    "glove = GloVe(name = '840B', \n",
    "              dim = GLOVE_DIM)\n",
    "\n",
    "print(f'Loaded {len(glove.itos)} words present in GloVe')\n",
    "\n",
    "embeddings_tensor = glove.vectors\n",
    "embeddings_tensor = embeddings_tensor.to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "# Generate 512 sentences\n",
    "NUM_SENT = 512\n",
    "sents = list()\n",
    "for i in range(NUM_SENT):\n",
    "    sents.append('This is the quest zero and it has a deadline this Sunday March 29')\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GloveEmbeddingAvg(nn.Module):\n",
    "    \n",
    "    def __init__(self, max_len):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings_tensor)\n",
    "        \n",
    "    def forward(self, \n",
    "                sent):\n",
    "        # Tokenize the sentence by spaces\n",
    "        tokens = sent.split(' ')[:self.max_len]\n",
    "        # Get idx of each token from the GloVe dictionary\n",
    "        glove_dict_indexes = [glove.stoi[token] for token in tokens]\n",
    "        # Convert it into Tensor\n",
    "        glove_dict_indexes = torch.tensor(glove_dict_indexes, \n",
    "                                          device = device)\n",
    "        # Get Word Embeddings for all tokens\n",
    "        word_embeds = self.embedding(glove_dict_indexes) # [MAX_LEN, GLOVE_DIM]\n",
    "        # Sentence Embedding = Average of Word Embeddings\n",
    "        sent_embeds = word_embeds.mean(dim = 0) # [GLOVE_DIM]\n",
    "        # Reshape Sentence Embedding as a 2D Tensor\n",
    "        return sent_embeds.view(1, -1) # [1, GLOVE_DIM]\n",
    "\n",
    "MAX_LEN = 10\n",
    "glove_embeds_avg = GloveEmbeddingAvg(MAX_LEN).to(device)\n",
    "\n",
    "print(glove_embeds_avg(sents[0]).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How will you modify step 1. so that the sentence embeddings are in $R^{50}$ ?\n",
    "BONUS: Can you think of more than one way to do this? What are the implications of each method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveEmbeddingAvg_50_Dim(nn.Module):\n",
    "    \n",
    "    def __init__(self, max_len):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings_tensor)\n",
    "        self.fc = nn.Linear(GLOVE_DIM, 50)\n",
    "        \n",
    "    def forward(self, \n",
    "                x):\n",
    "        # Slice each sentence to Max Length\n",
    "        x = x[:, :self.max_len]\n",
    "        # Get Word Embeddings for all tokens\n",
    "        word_embeds = self.embedding(x) # [BATCH_SIZE, MAX_LEN, GLOVE_DIM]\n",
    "        # Sentence Embedding = Average of Word Embeddings\n",
    "        sent_embeds = word_embeds.mean(dim = 0) # [MAX_LEN, GLOVE_DIM]\n",
    "        # Linear Layer to reduce Sentence Embedding Dimension to 50\n",
    "        return self.fc(sent_embeds) # [MAX_LEN, 50]\n",
    "\n",
    "MAX_LEN = 10\n",
    "glove_embeds_avg_50_dim = GloveEmbeddingAvg_50_Dim(MAX_LEN).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Quickly test your answer in step 2. with a batch of 512 sentences on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 50])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize a Sentence\n",
    "def tokenize(sent):\n",
    "    # Tokenize the sentence by spaces\n",
    "    tokens = sent.split(' ')\n",
    "    # Get idx of each token from the GloVe dictionary\n",
    "    glove_dict_indexes = [glove.stoi[token] for token in tokens]\n",
    "    return glove_dict_indexes\n",
    "\n",
    "# Create Tokenized Sentence Corpus\n",
    "tokenized_sents = list()\n",
    "for sent in sents:\n",
    "    tokenized_sents.append(tokenize(sent))\n",
    "tokenized_sents = torch.tensor(tokenized_sents, \n",
    "                               device = device)\n",
    "\n",
    "# Run forward pass\n",
    "BATCH_SIZE = 512\n",
    "for i in range(0, len(tokenized_sents), BATCH_SIZE):\n",
    "    batch = tokenized_sents[i:i+BATCH_SIZE]\n",
    "    sentence_embeddings = glove_embeds_avg_50_dim(batch)\n",
    "    print(sentence_embeddings.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You almost implemented the model in the Deep Averaging Networks (DAN) paper!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Task: \n",
    "### Create a   MultiEmbedding  Module that can take two sets of indices, embed them, and concat the results. You might remember it from the previous lecture where we had to produce an embedding for \"green apple\" from embeddings of \"green\" and \"apple\". Your  MultiEmbedding class should work with the following test code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_emb, \n",
    "                 size_emb1, \n",
    "                 size_emb2):\n",
    "        super().__init__()\n",
    "        self.embedding_A = nn.Embedding(num_emb, size_emb1)\n",
    "        self.embedding_B = nn.Embedding(num_emb, size_emb2)\n",
    "        \n",
    "    def forward(self, \n",
    "                indices1, \n",
    "                indices2):\n",
    "        embed_A = self.embedding_A(indices1)\n",
    "        embed_B = self.embedding_B(indices2)\n",
    "        # Concatenate the Embeddings\n",
    "        return torch.cat((embed_A, embed_B), \n",
    "                         dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 500])\n"
     ]
    }
   ],
   "source": [
    "# Test code: instantiate a MultiEmbedding with the sizes for each embedding. \n",
    "# For this example, you can just randomly initialize each interior embedding. \n",
    "# In a practical setting, you might support methods for initializing with \n",
    "# combinations of embeddings, such as GloVe 300d vectors and word2vec 200d \n",
    "# vectors, yielding 500d embeddings. Both embeddings share a vocabulary/range \n",
    "# of supported indices indicated by `num_emb`\n",
    "\n",
    "NUM_EMB = 10000\n",
    "SIZE_EMB1 = 300\n",
    "SIZE_EMB2 = 200\n",
    "BATCH_SIZE = 64\n",
    "NUM_LENGTH = 10\n",
    "\n",
    "multiemb = MultiEmbedding(NUM_EMB, \n",
    "                          SIZE_EMB1, \n",
    "                          SIZE_EMB2).to(device)\n",
    "\n",
    "# You can then call this with a pair of indices where each value is in 0 <= i < num_emb\n",
    "indices1 =  torch.randint(0, \n",
    "                          NUM_EMB, \n",
    "                          (BATCH_SIZE, NUM_LENGTH), \n",
    "                          dtype = torch.long, \n",
    "                          device = device) # long tensor of shape (batch, num_length)\n",
    "indices2 =  torch.randint(0, \n",
    "                          NUM_EMB, \n",
    "                          (BATCH_SIZE, NUM_LENGTH), \n",
    "                          dtype = torch.long, \n",
    "                          device = device) # long tensor of shape (batch, num_length)\n",
    "output = multiemb(indices1, \n",
    "                  indices2)\n",
    "print(output.shape) # should be (batch, num_length, size_emb1 + size_emb2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Datasets and DataLoaders: \n",
    "### Read this short post on PyTorch Dataset and DataLoaders. Often in prototyping we need to generate dummy datasets to test our models. Implement a PyTorch Dataset class that generates up to  num_sentences  random sentences of length up to  max_len words. For each sentence, generate a binary label. You should be able to test your code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAveragingNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, max_len):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings_tensor)\n",
    "        self.fc = nn.Linear(GLOVE_DIM, 50)\n",
    "        \n",
    "    def forward(self, \n",
    "                sent):\n",
    "        # Tokenize the sentence by spaces\n",
    "        tokens = sent.split(' ')[:self.max_len]\n",
    "        # Get idx of each token from the GloVe dictionary\n",
    "        glove_dict_indexes = [glove.stoi[token] for token in tokens]\n",
    "        # Convert it into Tensor\n",
    "        glove_dict_indexes = torch.tensor(glove_dict_indexes, \n",
    "                                          device = device)\n",
    "        # Get Word Embeddings for all tokens\n",
    "        word_embeds = self.embedding(glove_dict_indexes) # [MAX_LEN, GLOVE_DIM]\n",
    "        # Sentence Embedding = Average of Word Embeddings\n",
    "        sent_embeds = word_embeds.mean(dim = 0) # [GLOVE_DIM]\n",
    "        # Linear Layer to reduce Sentence Embedding Dimension to 50\n",
    "        return self.fc(sent_embeds.view(1, -1)) # [1, 50]\n",
    "\n",
    "model = DeepAveragingNetwork(MAX_LEN).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DummySentenceLabelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A simple dataset that generates random sentences and labels for each sentence.\n",
    "    Args:\n",
    "        num_sentences (int): The number of sentences to generate.\n",
    "        max_len (int): The maximum length of each sentence.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_sentences, \n",
    "                 max_len):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the given number of sentences and maximum sentence length.\n",
    "        Generates the sentences and labels using the generate_sents() and generate_labels() methods.\n",
    "        \"\"\"\n",
    "        self.num_sentences = num_sentences\n",
    "        self.max_len = max_len\n",
    "        self.sents = self.generate_sents()\n",
    "        self.labels = self.generate_labels()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of sentences in the dataset.\n",
    "        \"\"\"\n",
    "        return self.num_sentences\n",
    "        \n",
    "    def __getitem__(self, \n",
    "                    idx):\n",
    "        \"\"\"\n",
    "        Returns the sentence and label at the given index.\n",
    "        \"\"\"\n",
    "        return self.sents[idx], self.labels[idx]\n",
    "    \n",
    "    def get_random_sent(self, word_list):\n",
    "        \"\"\"\n",
    "        Generates a random sentence using the given list of words.\n",
    "        Args:\n",
    "            word_list (list): A list of words to choose from when generating the sentence.\n",
    "        Returns:\n",
    "            str: A sentence composed of randomly chosen words from the given list.\n",
    "        \"\"\"\n",
    "        sent = ''\n",
    "        for i in range(self.max_len):\n",
    "            word = random.choice(word_list)\n",
    "            sent += word + ' '\n",
    "        return sent\n",
    "    \n",
    "    def generate_sents(self):\n",
    "        \"\"\"\n",
    "        Generates a list of random sentences.\n",
    "        Uses the get_random_sent() method to generate each sentence.\n",
    "        Returns:\n",
    "            list: A list of randomly generated sentences.\n",
    "        \"\"\"\n",
    "        word_list = ['Hello', 'World', 'Python', 'Function', 'Random', 'Sentence', \n",
    "                     'List', 'Words', 'Generates', '20', 'Example', 'Simple', 'Program', \n",
    "                     'Easy', 'Understand', 'Learn', 'Code', 'Implement', 'Execute', 'Run', \n",
    "                     'Brazil', 'India', 'Chat', 'India', 'Golden', 'State', 'Warriors']\n",
    "        sents = list()\n",
    "        for i in range(self.num_sentences):\n",
    "            sent = self.get_random_sent(word_list)\n",
    "            sents.append(sent)\n",
    "        return sents\n",
    "    \n",
    "    def generate_labels(self):\n",
    "        \"\"\"\n",
    "        Generates a list of random labels (0 or 1) for each sentence.\n",
    "        Returns:\n",
    "            list: A list of randomly generated labels.\n",
    "        \"\"\"\n",
    "        labels = list()\n",
    "        for i in range(self.num_sentences):\n",
    "            labels.append(random.randint(0, 1))\n",
    "        return labels\n",
    "\n",
    "NUM_SENTENCES = 10\n",
    "MAX_LEN = 20\n",
    "dataset = DummySentenceLabelDataset(num_sentences = NUM_SENTENCES, \n",
    "                                    max_len = MAX_LEN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's measure the error rate for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Execute Golden Implement State 20 Warriors Simple India Sentence Program List Code Random Program 20 India Generates Random India Function ,\n",
      "Label: 1\n",
      "Sentence: Sentence Code Understand Words Implement Warriors Run India Chat Golden India Brazil Words Warriors Warriors Run Random Simple Understand Run ,\n",
      "Label: 1\n",
      "Sentence: Program Easy Function Sentence Function Program Words Simple Warriors Chat Words Understand Code Sentence Golden Learn Easy Sentence India Understand ,\n",
      "Label: 0\n",
      "Sentence: Understand India Words Random Function World 20 Chat Execute State Random Words Function Example India Python Golden World Warriors Program ,\n",
      "Label: 1\n",
      "Sentence: Random Brazil Example Implement Brazil Function State Program India Function Function State Golden Code Execute Execute Golden Example World Golden ,\n",
      "Label: 0\n",
      "Sentence: World Learn 20 Easy Golden Simple Python Golden Sentence Generates Brazil Easy World Easy State World Simple Words Generates List ,\n",
      "Label: 0\n",
      "Sentence: India Execute List Program Sentence Python Function Brazil Sentence India Implement Run Golden Code Run Implement Execute Random Implement Implement ,\n",
      "Label: 0\n",
      "Sentence: Execute Example Program List Implement Function Words Sentence Implement 20 Words Simple Easy List Hello Execute Random Chat Learn Sentence ,\n",
      "Label: 1\n",
      "Sentence: Code India India Generates Warriors Generates Warriors Hello Easy India List 20 India Brazil India Random List India List Chat ,\n",
      "Label: 1\n",
      "Sentence: Golden Execute Words Random Generates Execute State Easy World Hello Chat Simple World India Implement Code Words Python Program State ,\n",
      "Label: 1\n",
      "==================================================================\n",
      "Error rate: tensor([[0.5747, 0.6939, 0.6841, 0.6028, 0.5999, 0.6233, 0.6010, 0.5904, 0.6345,\n",
      "         0.6054, 0.6056, 0.6177, 0.6041, 0.7316, 0.5962, 0.5819, 0.7791, 0.5899,\n",
      "         0.7767, 0.6897, 0.5839, 0.5667, 0.7960, 0.6985, 0.5965, 0.7105, 0.6027,\n",
      "         0.5868, 0.6598, 0.6214, 0.6074, 0.5857, 0.7606, 0.6968, 0.7176, 0.6277,\n",
      "         0.7734, 0.7207, 0.7247, 0.6404, 0.5899, 0.6438, 0.6648, 0.5922, 0.7375,\n",
      "         0.6329, 0.5495, 0.6526, 0.6539, 0.6400]], device='mps:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "error = 0.0\n",
    "for sentence, label in dataset:\n",
    "  print(f'Sentence: {sentence},\\nLabel: {label}')\n",
    "  prediction = model(sentence)\n",
    "  error += abs(prediction - label)\n",
    "print('==================================================================')  \n",
    "print(f'Error rate: {error/len(dataset)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b37beb76676c8b0643f5764b5c5ae0ddf876ecbab29b433e279cae2d82963c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
