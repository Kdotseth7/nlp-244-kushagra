{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies\n",
    "Uncomment if running the notebook for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "import json\n",
    "import random\n",
    "import gdown\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.base import Chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_api_key = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_ai_api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go over the [LangChain](https://langchain.readthedocs.io/en/latest/index.html) documents and figure out how to set temperature for your requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_temp = 0.7\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", \n",
    "             temperature=default_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4.) Implement problem 3 using LangChain's LLM and the PromptTemplate classes and check if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_of_origin = \"India\"\n",
    "template_1 = \"Question: Come up with 10 girl baby names for babies born in {country_of_origin} which start with letter 'A and end with 'I.'\\nAnswer: \"\n",
    "prompt_1 = PromptTemplate(template=template_1, \n",
    "                          input_variables=[\"country_of_origin\"])\n",
    "formatted_prompt_1 = prompt_1.format(country_of_origin=country_of_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Come up with 10 girl baby names for babies born in India which start with letter 'A and end with 'I.'\n",
      "Answer: \n",
      "1. Aashi \n",
      "2. Amri \n",
      "3. Asmi \n",
      "4. Anvi \n",
      "5. Arvi \n",
      "6. Aarvi \n",
      "7. Ayushi \n",
      "8. Aditi \n",
      "9. Aashiqi \n",
      "10. Aasri\n"
     ]
    }
   ],
   "source": [
    "llm_answer_1 = llm(formatted_prompt_1)\n",
    "print(f\"{formatted_prompt_1}{llm_answer_1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.) Create a new prompt that takes a baby name and the country of origin, and comes up with a short (made up) biography. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_name = \"Kunal\"\n",
    "country_of_origin = \"India\"\n",
    "template_2 = \"Question: Come up with a short (made up) biography for a baby named {baby_name}, born in {country_of_origin}.\\nAnswer: \"\n",
    "prompt_2 = PromptTemplate(template=template_2, \n",
    "                         input_variables=[\"country_of_origin\", \"baby_name\"])\n",
    "formatted_prompt_2 = prompt_2.format(baby_name=baby_name, \n",
    "                                     country_of_origin=country_of_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Come up with a short (made up) biography for a baby named Kunal, born in India.\n",
      "Answer: \n",
      "Kunal was born in India to loving parents who were excited to welcome him into the world. Growing up, Kunal was a curious and vibrant child, always eager to explore and try new things. He loved the outdoors, playing games with his friends, and learning about his culture. Kunal grew up to be an intelligent and kind-hearted young man, and he continues to explore the world around him with a deep curiosity. He is passionate about making a difference and is always looking for new ways to help those around him.\n"
     ]
    }
   ],
   "source": [
    "llm_answer_2 = llm(formatted_prompt_2)\n",
    "print(f\"{formatted_prompt_2}{llm_answer_2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.) Follow the [LangChain example to create a custom chain class](https://langchain.readthedocs.io/en/latest/modules/chains/getting_started.html#create-a-custom-chain-with-the-chain-class), to create class that returns a list of dicts of {baby_name, biography}. You have to use the prompts you created in 4 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Chain Output:\n",
      "[{'baby_name': 'Abhiri', 'biography': 'Abhiri is a happy baby born in India to loving parents. She loves to giggle, smile, and explore her world. She loves playing with her stuffed animals and enjoys learning new things. She loves spending time with her family and is always up for a cuddle. Abhiri is a bright and curious little girl who loves life and is full of joy.'}, {'baby_name': 'Adhiti', 'biography': 'Adhiti was born in India to a loving family. She came into the world full of life and ready to explore. As she grows, she is a curious child who loves to learn and ask questions. She is an adventurous soul who loves to explore her surroundings and find new things to do. She is passionate about music and loves to sing and dance. Adhiti is a bright and happy baby who brings joy to all she meets.'}, {'baby_name': 'Ahanti', 'biography': \"Ahanti is a newborn baby from India, born into a loving and supportive family. She is a bundle of joy and her parents are delighted to welcome her into the world. Ahanti is already showing an interest in music, as she can often be found humming a tune or tapping out rhythms on objects around her. Her parents are looking forward to seeing what the future holds for her and are sure she'll be a bright and successful child.\"}, {'baby_name': 'Amriti', 'biography': 'Amriti was born in India to loving parents. She is a bright and bubbly baby who loves to explore her surroundings. She loves to play with her toys and loves to cuddle with her parents. Amriti is a very curious baby with a keen interest in learning new things. She is a fast learner and loves to listen to stories. Amriti loves to be around people and is always eager to make new friends. She is a happy and content baby who loves to laugh and enjoy life to the fullest.'}, {'baby_name': 'Anjali', 'biography': 'Anjali is a beautiful baby girl born in India. She loves to explore the world around her and is always filled with joy and wonder. She loves to listen to music and dance along with her family. Anjali is always eager to learn and loves to laugh and play with her friends. She is a bright and loving addition to her family and is loved by all who know her.'}, {'baby_name': 'Arpiti', 'biography': 'Arpiti was born in India to an adoring family. She is a sweet and energetic baby who loves to explore and learn new things. She loves to be around people and has an infectious smile that always lights up the room. She is curious and loves to try new things, and her parents are always amazed at her progress. Arpiti loves spending time outdoors and loves to play with her siblings and friends. She is an adventurous spirit who loves to travel and discover new places. Arpiti is a bright and happy baby who brings joy and laughter to all who know her.'}, {'baby_name': 'Ashini', 'biography': 'Ashini was born in India to a loving family. She is a happy, curious baby who loves to explore. She loves to play with her toys and is always trying to learn new things. She loves to be around her family, and she loves to be cuddled and kissed. Ashini loves to laugh and smile and is a constant source of joy for her parents and everyone around her.'}, {'baby_name': 'Avani', 'biography': 'Avani was born in India to two loving parents who were overjoyed at their new addition. From the start, Avani was a curious and outgoing baby. As a toddler, she loved to explore her surroundings, playing with her toys and making friends wherever she went. Growing up, Avani developed a passion for learning and was always eager to try new things. She was a bright student and was active in her school and community, participating in various clubs and activities. Now, at the age of 8, Avani loves spending time with her family, reading books, playing sports, and learning new things. She is a bright and positive spirit, and she looks forward to a bright future ahead.'}, {'baby_name': 'Ayushi', 'biography': \"Ayushi was born in India in the spring of 2021. She is the first child of her parents, who are thrilled to welcome her into the world. As a baby, Ayushi loves to explore her surroundings and enjoys playing with her toys. She loves to giggle and smile, and her parents are overjoyed to see her happy. She loves music and loves to be held by her parents. Ayushi is a bright and beautiful baby, and her parents can't wait to watch her grow and learn new things.\"}, {'baby_name': 'Azrai', 'biography': 'Azrai was born in India to loving parents. From a young age, she was fascinated by the world around her, eager to explore and learn. As a toddler, she enjoyed playing outdoors and making friends. Azrai loved to sing and dance, and she often entertained her family with her lively performances. As she grew, her curiosity only increased, and she developed a passion for science and the arts. Azrai is now a bright and inquisitive young girl who loves to explore and is full of enthusiasm for life.'}]\n"
     ]
    }
   ],
   "source": [
    "class CustomChain(Chain):\n",
    "    # Baby name generator chain\n",
    "    chain_1: LLMChain\n",
    "    # Biography generator chain\n",
    "    chain_2: LLMChain\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        return list(self.chain_1.input_keys)\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return ['output']\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]):\n",
    "        results = list()\n",
    "        # Get a list of baby names from the first chain\n",
    "        output_1 = self.chain_1.run(inputs)\n",
    "        output_1 = output_1.strip().splitlines()\n",
    "        # For each baby name, get a biography from the second chain\n",
    "        for i in output_1:\n",
    "            temp = dict()\n",
    "            baby_name = i.split(' ')[1]\n",
    "            inputs['baby_name'] = baby_name\n",
    "            output_2 = self.chain_2.run(inputs).strip()\n",
    "            temp['baby_name'] = baby_name\n",
    "            temp['biography'] = output_2\n",
    "            results.append(temp)\n",
    "        return {'output': results}\n",
    "    \n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
    "\n",
    "custom_chain = CustomChain(chain_1=chain_1, chain_2=chain_2)\n",
    "custom_chain_output = custom_chain.run(country_of_origin=country_of_origin)\n",
    "print(f\"Custom Chain Output:\\n{custom_chain_output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArXiv Bulletin\n",
    "Every day several hundred, if not more, papers appear on ArXiv. For this task you will implement an ArXiv bulletin that gives a list of paper titles and why I should read it in one sentence. Your final output should look something like this (the exact papers will be different):\n",
    "\n",
    "1. Summarizing Encyclopedic Term Descriptions on the Web <br/>\n",
    "Why to read: This paper presents a summarization method to produce a single text from multiple descriptions to concisely describe a term from different viewpoints. <br/>\n",
    "2. Unsupervised Topic Adaptation for Lecture Speech Retrieval <br/>\n",
    "Why to read: This paper presents a novel approach to improve the quality of a cross-media information retrieval system by adapting acoustic and language models for automatic speech recognition. <br/>\n",
    "\n",
    "Download a sample of the NLP ArXiv dataset from here. It has metadata for 100 NLP papers as JSON records. For this exercise, you will randomly pick 10 records to show a proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_1oPRNSW7QWdlUs-APMV5Y7h6RxU_8gF\n",
      "To: /Users/kushagraseth/Documents/Repositories/nlp-244-kushagra/quest-2/cs.cl.sample100.json\n",
      "100%|██████████| 135k/135k [00:00<00:00, 1.89MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Research Papers:\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gdown.download('https://drive.google.com/uc?id=1_1oPRNSW7QWdlUs-APMV5Y7h6RxU_8gF')\n",
    "with open('cs.cl.sample100.json') as f:\n",
    "    data = f.readlines()\n",
    "parsed = [json.loads(x) for x in data]\n",
    "sample10 = random.choices(parsed, k=10)\n",
    "# paper_list is a list of tuples of the form (title, abstract)\n",
    "paper_list = [(i['title'].strip(), i['abstract'].strip()) for i in sample10]\n",
    "print(f\"Number of Research Papers:\\n{len(paper_list)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have to use LangChain for this problem and come up with a suitable zero-shot prompt for \"why\". Be creative with your prompts and use the prompting best practices as your guide. You can experiment with a few prompt variations on for a single paper in Playground before you use it in your code. Make sure your code runs at T=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_temp = 0\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", \n",
    "             temperature=new_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effects of Language Modeling on Speech-driven Question Answering.\n",
      "Why to read: \n",
      "This paper presents a novel approach to speech-driven question answering by integrating automatic speech recognition and question answering, and evaluates its performance using a TREC-style evaluation workshop.\n",
      "\n",
      "Proofing Tools Technology at Neurosoft S.A..\n",
      "Why to read: \n",
      "This paper provides an overview of the development of proofing tools for Modern Greek at Neurosoft S.A., discussing their efficiencies and inefficiencies, as well as improvement ideas and future directions, making it an essential read for NLP students.\n",
      "\n",
      "Mapping Multilingual Hierarchies Using Relaxation Labeling.\n",
      "Why to read: \n",
      "This paper presents a new and robust approach for automatically constructing a multilingual Lexical Knowledge Base from pre-existing lexical resources, which could be applied to enrich and improve existing NLP databases.\n",
      "\n",
      "Thematic Annotation: extracting concepts out of documents.\n",
      "Why to read: \n",
      "This paper presents a novel approach to topic annotation that uses a large scale semantic database to extract the most relevant set of concepts to represent the topics discussed in the document.\n",
      "\n",
      "Analyzing language development from a network approach.\n",
      "Why to read: \n",
      "This paper provides a new approach to study language development using network analyses, which can help NLP students gain insights into the syntactic development of language.\n",
      "\n",
      "Explanation-based Learning for Machine Translation.\n",
      "Why to read: \n",
      "This paper presents an application of explanation-based learning to a real-time English-Spanish machine translation system, demonstrating its effectiveness in increasing coverage while maintaining a high level of space and time efficiency.\n",
      "\n",
      "Challenging the principle of compositionality in interpreting natural\n",
      "  language texts.\n",
      "Why to read: \n",
      "This paper proposes an alternative approach to interpreting natural language texts that challenges the principle of compositionality.\n",
      "\n",
      "Restrictions on Tree Adjoining Languages.\n",
      "Why to read: \n",
      "This paper provides an algorithm for parsing a strict subclass of Tree Adjoining Grammars (TAGs) in O(n^5) time complexity, which retains enough generative power to be useful for NLP applications.\n",
      "\n",
      "Learning Transformation Rules to Find Grammatical Relations.\n",
      "Why to read: \n",
      "This paper presents a trainable approach to finding grammatical relationships between core syntax groups, which can be used to bypass much of the parsing phase in NLP tasks.\n",
      "\n",
      "Robust Grammatical Analysis for Spoken Dialogue Systems.\n",
      "Why to read: \n",
      "This paper provides an overview of a robust grammatical analysis approach for spoken dialogue systems, which combines linguistic and statistical sources of information to achieve fast and accurate processing of spoken input.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in paper_list:\n",
    "    paper_title = i[0]\n",
    "    abstract = i[1]\n",
    "    template =  \"\"\"Research Paper Title: {paper_title}.\\nAbstract: {abstract}.\\nSummarize in one sentence why should \n",
    "    I read this paper as an Natural Language Processing (NLP) student given Research Paper's Title and Abstract: \n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=template, \n",
    "                            input_variables=[\"paper_title\", \"abstract\"])\n",
    "    formatted_prompt = prompt.format(paper_title=paper_title, \n",
    "                                     abstract=abstract)\n",
    "    llm_answer = llm(formatted_prompt)\n",
    "    print(f\"{paper_title}.\\nWhy to read: {llm_answer}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2c87e16e3c5224f19fdcd75f65d952c55b5bf326ebfd42c1280c69b64e015be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
